# Những thuật ngữ cơ bản về AI và Machine Learning (Phần 1)
## A
- ### Algorithm

**_Thuật toán_**, còn gọi là giải thuật, là một tập hợp hữu hạn hay một dãy các qui tắc chặt chẽ của các chỉ thị, phương cách hay 1 trình tự các thao tác trên một đối tượng cụ thể được xác định và định nghĩa rõ ràng cho việc hoàn tất một số sự việc từ một trạng thái ban đầu cho trước; khi các chỉ thị này được áp dụng triệt để thì sẽ dẫn đến kết quả sau cùng như đã dự đoán trước. Thuật toán là nền tảng tạo nên Machine Learning và AI. Mục tiêu của thuật toán là dạy cho AI, mạng nerural hay các loại máy móc khác cách có thể tự mình học mọi thứ. Các thuật toán cơ bản trong Machine Learning: Clustering (Phân cụm), Classification (Phân loại), Regression(Hồi quy), và Recommendation (Gợi ý).
- ### Analytical Validation

**_Analytical Validation_** (Xác nhận kết quả phân tích) là sự tính toán độ chính xác, tin cậy kết quả đầu ra của một kỹ thuật nhất định với dữ liệu đầu vào cụ thể. Các kỹ thuật xác nhận kết quả trong machine learning đưa ra tỉ lệ lỗi của các machine learning model. Các kỹ thuật phổ biến: Resubstitution, K-fold cross-validation, Random subsampling, Bootstrapping.
- ### Artificial general intelligence (AGI)

**_Artificial general intelligence (AGI)_**, strong AI và superintelligence đều dùng để chỉ một loại trí tuệ nhân tạo thông minh ngang bằng hoặc vượt trội so với con người, áp dụng trong mọi mặt, mọi phương diện. Đây là loại AI mới chỉ xuất hiện trong các bộ phim bom tấn. Hiện tại, chúng ta chưa đạt tới được mức độ này. Ngược lại với nó là weak AI (hay Artificial narrow intelligence (ANI))
- ### Artificial Intelligence (AI)

> "**_Artificial Intelligence_** (AI - Trí tuệ nhân tạo) là công nghệ và kỹ thuật tạo ra những cỗ máy thông minh, đặc biệt là những chương trình máy tính."-Alan Turing

AI là một chuyên ngành của khoa học máy tính nhằm mục đích xây dựng những cỗ máy có khả năng thực hiện các nhiệm vụ giống con người: ra quyết định, phân loại, phát hiện đối tượng, nhận dạng giọng nói và dịch thuật.

Trí tuệ nhân tạo và học máy có liên quan với nhau. ML là một chuyên ngành của AI. Cả AI và ML là một tập hợp các thuật toán, nhưng ML chỉ có thể được cung cấp dữ liệu có cấu trúc còn AI có thể xử lý cả các thông tin có cấu trúc và không cấu trúc để hoàn thành một nhiệm vụ mà không được lập trình cách thực hiện.
### Artificial narrow intelligence (ANI)

**_Artificial narrow intelligence (ANI)_**, còn được gọi là weak AI, là AI chỉ tập trung thực hiện tốt một nhiệm vụ, chẳng hạn như thu thập dữ liệu trang web hoặc chơi cờ (nó được sử dụng trong việc xây dựng các trợ lý ảo như Siri).
- ### Artificial neural network (ANN)

**_Artificial neural network (ANN)_** (Mạng nơ-ron nhân tạo) là một mô hình được sử dụng trong AI được lấy cảm hứng từ mạng lưới thần kinh sinh học cấu thành bộ não động vật. Nó bao gồm các lớp nơ-ron được sử dụng cho ML. Các hệ thống như vậy học hỏi bằng cách xem xét các ví dụ để thực hiện các nhiệm vụ mà không được lập trình bất kỳ quy tắc cụ thể nào về nhiệm vụ.
- ### Augmented Intelligence (hay còn được gọi là Intelligence Augmentation (IA))

**_Augmented Intelligence_** là hệ thống giúp đỡ, hỗ trợ con người thực hiện nhiệm vụ một cách nhanh chóng và thông minh hơn.

## B
- ### Backpropagation
**_Backpropagation_** (viết tắt của "backward propagation of errors") là cách mà mạng nơ-ron học. Đó là phương tiện cho mạng nơ-ron biết mạng có đưa ra dự đoán sai lầm không bằng cách truyền ánh sáng, âm thanh, chuyển động hoặc thông tin theo một hướng cụ thể hoặc thông qua một phương tiện cụ thể.  

- ### Bayesian networks
**_Bayesian networks_** còn được gọi là mạng nhân quả, mạng niềm tin hay mạng quyết định, Bayesian Networks là các mô hình đồ họa để đại diện cho các phân phối xác suất đa biến nhằm mục đích mô hình hóa sự phụ thuộc có điều kiện. Nó thể hiện quan hệ nhân quả bằng cách biểu diễn sự phụ thuộc có điều kiện bởi các cạnh trong một biểu đồ có hướng.

- ### Big data
**_Big data_** là một lượng lớn dữ liệu có cấu trúc và không cấu trúc quá phức tạp để được xử lý bởi phần mềm xử lý dữ liệu tiêu chuẩn.

## C
- ### Chatbots
**_Chatbots_** là một chương trình được sử dụng để chạy giao diện messenger. Chức năng chính là nhận ra yêu cầu của người đối thoại và trả lời lại một cách phù hợp. Một chatbot mô phỏng một cuộc trò chuyện thực sự với người dùng thông qua tin nhắn văn bản hoặc giọng nói.
Chatbots sử dụng ML để xác định các mẫu giao tiếp. Thông qua sự tương tác liên tục với mọi người, nó học cách bắt chước các cuộc trò chuyện thực tế và trả lời các câu hỏi bằng lời nói hoặc bằng văn bản. Do đó, sau mỗi cuộc đối thoại, nó trở nên thông minh hơn.

- ### Classification
Trong ML và thống kê, **_Classification_** (phân loại) là một thuật toán học có giám sát, cho phép máy tính gán các danh mục cho các điểm dữ liệu (phân loại dữ liệu thành một số lớp nhất định). Phân loại (cây quyết định và phân loại mạng nơ-ron) có thể được sử dụng để phân loại văn bản trong marketing.

- ### Clustering
**_Clustering_** (Phân cụm) là một kỹ thuật của Machine Learning liên quan tới việc nhóm các điểm dữ liệu. Phân cụm là thuật toán học không giám sát và là một kỹ thuật phổ biến để phân tích dữ liệu thống kê được sử dụng trong nhiều lĩnh vực. Phân cụm được sử dụng với các ứng dụng bao gồm phân khúc khách hàng, tìm kiếm nhanh và trực quan hóa dữ liệu.

- ### Cognitive computing
**_Cognitive computing_** (CC - Điện toán nhận thức)  là một thuật ngữ khác thường được sử dụng thay thế cho trí tuệ nhân tạo. Tuy nhiên, 2 khái niệm này có những điểm khác biệt. Nó đề cập đến một kỷ nguyên mới của siêu điện toán, nơi máy tính bắt chước hoạt động của não bộ con người và giúp đưa ra quyết định tốt hơn. Việc đưa ra quyết định thay cho con người là điểm mấu chốt làm cho Cognitive Computing khác biệt với AI. Để phân tích một lượng lớn dữ liệu, cognitive computer (máy tính nhận thức) có thể sử dụng AI, deep learning, machine learning, text mining (trích xuất và xử lý thông tin trong văn bản), trợ lý giọng nói hoặc neuro-linguistic programming (NLP - lập trình ngôn ngữ tư duy). Điều này giúp các nhà khoa học và những nhà nghiên cứu giải quyết nhanh chóng mọi vấn đề, áp dụng các giả thuyết mới và mở rộng mô hình của mình.
 ![alt text](https://cdn-images-1.medium.com/max/1600/0*P38UoaO4xeTIe7gq)
 
 - ### Computer Aided Detection (CADe)
 **_Computer Aided Detection (CADe)_** là các hệ thống hỗ trợ bác sĩ trong việc giải thích các hình ảnh y tế. Các kỹ thuật hình ảnh trong X-quang, MRI và chẩn đoán siêu âm mang lại rất nhiều thông tin mà bác sĩ X quang hoặc chuyên gia y tế khác phải phân tích và đánh giá toàn diện trong một thời gian ngắn. Các hệ thống CAD xử lý hình ảnh kỹ thuật số để làm nổi bật các phần dễ thấy, chẳng hạn như các triệu chứng bệnh có thể, cung cấp dữ liệu để hỗ trợ quyết định của chuyên gia.
 
 - ### Computer vision
 **_Computer vision_** (Thị giác máy tính) một lĩnh vực bao gồm các phương pháp thu nhận, xử lý ảnh kỹ thuật số, phân tích và nhận dạng các hình ảnh và, nói chung là dữ liệu đa chiều từ thế giới thực để cho ra các thông tin số hoặc biểu tượng, ví dụ trong các dạng quyết định. Việc phát triển lĩnh vực này có bối cảnh từ việc sao chép các khả năng thị giác con người bởi sự nhận diện và hiểu biết một hình ảnh mang tính điện tử. Sự nhận diện hình ảnh có thể xem là việc giải quyết vấn đề của các biểu tượng thông tin từ dữ liệu hình ảnh qua cách dùng các mô hình được xây dựng với sự giúp đỡ của các ngành lý thuyết học, thống kê, vật lý và hình học. Thị giác máy tính cũng được mô tả là sự tổng thể của một dải rộng các quá trình tự động và tích hợp và các thể hiện cho các nhận thức thị giác.

Thị giác máy tính là một môn học khoa học liên quan đến lý thuyết đằng sau các hệ thống nhân tạo có trích xuất các thông tin từ các hình ảnh. Dữ liệu hình ảnh có thể nhiều dạng, chẳng hạn như chuỗi video, các cảnh từ đa camera, hay dữ liệu đa chiều từ máy quét y học. Thị giác máy tính còn là một môn học kỹ thuật, trong đó tìm kiếm việc áp dụng các mô hình và các lý thuyết cho việc xây dựng các hệ thống thị giác máy tính.
 ![](https://cdn-images-1.medium.com/max/1600/0*MS8y12ytOa8MXN6f.gif)
- ### Confidence Interval
**_Confidence Interval_** là một loại ước lượng khoảng, được tính từ số liệu thống kê của dữ liệu quan sát được, có thể bao hàm giá trị thực của tham số quần thể chưa biết. Khoảng có một độ tin cậy tương ứng, nói một cách chung chung, ước lượng độ tin cậy mà tham số nằm trong khoảng. Nói đúng hơn, độ tin cậy biểu thị tần số (nghĩa là tỷ lệ) của các khoảng tin cậy có thể có chứa giá trị thực của tham số quần thể chưa biết. Nói cách khác, nếu các khoảng tin cậy được xây dựng bằng cách sử dụng một độ tin cậy nhất định từ một con số thống kê mẫu độc lập vô hạn, tỷ lệ của các khoảng đó chứa giá trị thực của tham số sẽ bằng với độ tin cậy.

- ### Continuous Learning Systems (CLS)
**_Continuous Learning Systems (CLS)_** là các hệ thống có khả năng học hỏi từ dữ liệu trong thế giới thực và có thể tự cập nhật theo thời gian trong khi sử dụng.

- ### Convolutional neural network (CNN) 
**_Convolutional neural network (CNN)_** (Mạng nơ-ron tích chập) là một trong những mô hình Deep Learning tiên tiến giúp cho chúng ta xây dựng được những hệ thống thông minh với độ chính xác cao như hiện nay như hệ thống xử lý ảnh lớn như Facebook, Google hay Amazon đã đưa vào sản phẩm của mình những chức năng thông minh như nhận diện khuôn mặt người dùng, phát triển xe hơi tự lái hay drone giao hàng tự động.

## D
- ### Data mining 
**_Data mining_** là quá trình tính toán để tìm ra các mẫu trong các bộ dữ liệu lớn liên quan đến các phương pháp tại giao điểm của máy học, thống kê và các hệ thống cơ sở dữ liệu. Đây là một lĩnh vực liên ngành của khoa học máy tính. Mục tiêu tổng thể của quá trình khai thác dữ liệu là trích xuất thông tin từ một bộ dữ liệu và chuyển nó thành một cấu trúc dễ hiểu để sử dụng tiếp. Ngoài bước phân tích thô, nó còn liên quan tới cơ sở dữ liệu và các khía cạnh quản lý dữ liệu, xử lý dữ liệu trước, suy xét mô hình và suy luận thống kê, các thước đo thú vị, các cân nhắc phức tạp, xuất kết quả về các cấu trúc được phát hiện, hiện hình hóa và cập nhật trực tuyến. Khai thác dữ liệu là bước phân tích của quá trình "khám phá kiến thức trong cơ sở dữ liệu" hoặc KDD.

- ### Deep learning
**_Deep learning_** là một phương pháp của ML. Nó cho phép chúng ta huấn luyện một AI có thể dự đoán được các đầu ra dựa vào một tập các đầu vào. Cả hai phương pháp có giám sát và không giám sát đều có thể sử dụng để huấn luyện. Deep Learning là một thuật toán dựa trên một số ý tưởng từ não bộ tới việc tiếp thu nhiều tầng biểu đạt, cả cụ thể lẫn trừu tượng, qua đó làm rõ nghĩa của các loại dữ liệu. Deep Learning được ứng dụng trong nhận diện hình ảnh, nhận diện giọng nói, xử lý ngôn ngữ tự nhiên.Điểm đặc biệt của Deep Learning là tính chính xác dựa vào lượng dữ liệu, lượng dữ liệu có thể có kích thước khổng lồ mà không bị hạn chế.
 ![alt_text](https://cdn-images-1.medium.com/max/1400/0*dKYLdxDWbZIt609i)

